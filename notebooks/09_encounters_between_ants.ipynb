{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encounters between ants\n",
    "Function to calculate the encounters between specific ants (e.g., focal and caregiver ants) from a ```.mymridon``` experiment file. <br><br>\n",
    "There is probably an easier way to do this by querying individual frames directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta  # For convenient handling of time and date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  # Used to create a dataframe, similar to the structure used in R\n",
    "import py_fort_myrmidon as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to output trajectories of all ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trajectory_output_all(start_time, end_time, exp):\n",
    "    \"\"\"\n",
    "    Function to extract daily trajectories, grouped by AntID. While it is setup to extract daily trajectories, it can work for any arbitrary time duration\n",
    "    :param start_time: The start datetime object. this will be converted to a fort-myrmidon Time object\n",
    "    :param end_time: The end datetime object. this will be converted to a fort-myrmidon Time object\n",
    "    :param exp: The name of the experiment i.e., the myrmidon file\n",
    "    :param matcher_query: The fm matcher corresponding to the focal IDs\n",
    "    :return: Outputs a pandas dataframe containing AntID, Space, Time, X_coordinates and Y_coordinates of each ID averaged over 1 second from the X and Y coordinates. Averagingg is done to have a dataset which can be merged across IDs using at the resolution of 1s.\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    t_begin = fm.Time(start_time)\n",
    "    t_stop = fm.Time(end_time)\n",
    "    trajectory = fm.Query.ComputeAntTrajectories(\n",
    "        experiment=exp,\n",
    "        start=t_begin,\n",
    "        end=t_stop,\n",
    "        # matcher=matcher_query,\n",
    "        maximumGap=fm.Duration.Parse(\"1000h\"),\n",
    "        reportProgress=False,\n",
    "    )\n",
    "    # Make a list of lists with trajectory values needed. Position is an array of 5 columns, so specific columns are called\n",
    "    traj_list = [\n",
    "        [\n",
    "            trajectory.Ant,\n",
    "            trajectory.Space,\n",
    "            trajectory.Start.ToDateTime(),\n",
    "            trajectory.Positions[:, 0],\n",
    "            trajectory.Positions[:, 1],\n",
    "            trajectory.Positions[:, 2],\n",
    "        ]\n",
    "        for trajectory in trajectory\n",
    "    ]\n",
    "    # Make the list into a dataframe\n",
    "    traj_df = pd.DataFrame(\n",
    "        traj_list,\n",
    "        columns=[\"AntID\", \"Space\", \"StartTime\", \"Pos_time\", \"X_coor\", \"Y_coor\"],\n",
    "    )\n",
    "    # Explode columns which are in the form of lists to expand the dataframe\n",
    "    traj_df = traj_df.explode(column=[\"Pos_time\", \"X_coor\", \"Y_coor\"])\n",
    "    # Coerce coordinates to integer\n",
    "    traj_df[\"X_coor\"] = pd.to_numeric(traj_df[\"X_coor\"], errors=\"coerce\")\n",
    "    traj_df[\"Y_coor\"] = pd.to_numeric(traj_df[\"Y_coor\"], errors=\"coerce\")\n",
    "    # Convert Pos_time to timedelta and obtain actual datetime for each trajectory entry\n",
    "    traj_df[\"Pos_time\"] = pd.to_numeric(traj_df[\"Pos_time\"], errors=\"coerce\")\n",
    "    traj_df[\"Pos_time\"] = pd.to_timedelta(\n",
    "        traj_df[\"Pos_time\"], unit=\"S\", errors=\"coerce\"\n",
    "    )\n",
    "    traj_df[\"Time\"] = traj_df[\"StartTime\"] + traj_df[\"Pos_time\"]\n",
    "    # Drop unwanted ccolumns\n",
    "    traj_df = traj_df.drop([\"StartTime\", \"Pos_time\"], axis=1)\n",
    "    # Reorder columns\n",
    "    traj_df = traj_df[[\"AntID\", \"Space\", \"Time\", \"X_coor\", \"Y_coor\"]]\n",
    "    if traj_df.empty:  # If no trajectories are output\n",
    "        # empty_row = pd.DataFrame([{'AntID': 'Unknown', 'Space':np.nan, 'Time':np.nan, 'X_coor':np.nan, 'Y_coor':np.nan}]) # Create empty row with unknown as antID\n",
    "        # traj_df = pd.concat([empty_row]) # Add empty row to dataframe\n",
    "        print(\"No trajectories found. Created empty dataframe\")\n",
    "        return traj_df  # Return empty dataframe\n",
    "    # Obtain average X and Y coordinates per second\n",
    "    # traj_df = (\n",
    "    #     traj_df.groupby([pd.Grouper(key=\"Time\", freq=\"1s\"), \"AntID\", \"Space\"])\n",
    "    #     .agg(X_mean=(\"X_coor\", \"mean\"), Y_mean=(\"Y_coor\", \"mean\"))\n",
    "    #     .reset_index()\n",
    "    # )\n",
    "    end = datetime.now()\n",
    "    # print(\"Trajectories output in\", end-start)\n",
    "    return traj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate duration of encounters\n",
    "This function will calculate the duration of time an ant spends in the encounter zone after moving from the away zone to the encounter zone. This will require first identifying instances of an encounter, then calculating duration when the ant is within the encounter threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run over each sequence of encounters to extract sub-sequences where individuals are within the encounter threshold (enc_dummy=1).\n",
    "# The number and total duration of these sequences is output\n",
    "def time_within_encounter_threshold(displacement_dataset, encounter_sequence):\n",
    "    \"\"\"Function to quantify sub-sequences when an individual is within the encounter threshold during an encounter.\n",
    "    These sub-sequences have a enc_dummy value of 1. The function extracts these sub-sequences, obtains their start and end time points\n",
    "    from the displacment dataset and outputs the number and total duration of all sub-sequences within an encounter sequence.\n",
    "    Note that the encounter sequence should only contain values of 0.5 and 1, since an encounter by definition is within two instances of enc_dummy == 0\n",
    "\n",
    "    Args:\n",
    "        displacement_dataset (pandas.DataFrame): A pandas dataframe which contains at least the main index values and a column with Time\n",
    "        encounter_sequence (numpy.array): A numpy array containing the sequence of enc_dummy values with 0.5 and 1 corresponding to when displacement is within away threshold and within encounter threshold\n",
    "\n",
    "    Returns:\n",
    "        total_enc (int): The number of sub-sequences which are within the encounter threshold\n",
    "        total_enc (numpy.float64): The total duration of all sub-sequences which are within the encounter threshold\n",
    "    \"\"\"\n",
    "    # Add 0.5 to end of the list, then find out indices where consecutive difference is not 0\n",
    "    change_indices = np.where(\n",
    "        np.diff(np.concatenate(([0.5], encounter_sequence, [0.5]))) != 0\n",
    "    )[0]\n",
    "    # Get start indices starting from the bginning and jumping by 2 upto the end\n",
    "    start_indices = [encounter_sequence.index.values[x] for x in change_indices[::2]]\n",
    "    # Get end indices starting from 1 going upto the end jumping by 2. Subtract 1 from all index values to account for the extra value added at the concatenation step\n",
    "    end_indices = [encounter_sequence.index.values[x] for x in change_indices[1::2] - 1]\n",
    "    # Get time of starting indices\n",
    "    start_times = [displacement_dataset.loc[x, \"Time\"] for x in start_indices]\n",
    "    # Get time of ending indices\n",
    "    end_times = [displacement_dataset.loc[x, \"Time\"] for x in end_indices]\n",
    "    # Get time duration within encounter thresholds by subtraction\n",
    "    enc_times = np.subtract(end_times, start_times)\n",
    "    enc_times_sec = [x.total_seconds() for x in enc_times]\n",
    "    # Obtain total time and number of times ants are within encounter threshold consecutively\n",
    "    total_enc_times = np.sum(enc_times_sec)\n",
    "    total_enc = len(enc_times_sec)\n",
    "    return total_enc, total_enc_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encounter_duration(displacement_dataset, encounter_threshold, away_threshold):\n",
    "    \"\"\"Function to calculate duration of encounters between a focal ant and another individual.\n",
    "    Encounters are defined as when an ant moves from beyond the away threshold to within the encounter threshold with respect to the focal ant.\n",
    "    Two metrics of encounter duration are calculated - one based on the total time from when an ant moves within the encounter threshold to when it crosses the away threshold again\n",
    "    and another based on only the total time spent within the encounter threshold during the encounter\n",
    "    Outputs a dataframe with these durations calculated for each encounter between the 2 ants\n",
    "\n",
    "    Args:\n",
    "        displacement_dataset (pandas.DataFrame): A pandas dataframe containing at least Timestamps and displacement between 2 ants at each timestamp. It should also contain an index which is used to match sequence starts and stops to timestamps\n",
    "        encounter_threshold (int): The value of displacement for the encounter threshold\n",
    "        away_threshold (int): The value of displacement for the away threshold\n",
    "\n",
    "    Returns:\n",
    "        enc_df(pandas.DataFrame): A dataframe containing the number of the encounter, the start time, total duration,\n",
    "    number of times within the encounter where the displacement between the two ants were within the encounter threshold and the total duration of these phases\n",
    "    \"\"\"\n",
    "    # First interpolate (linearly) missing displacement values\n",
    "    displacement_dataset[\"disp\"].interpolate(\n",
    "        method=\"linear\", limit_direction=\"forward\", inplace=True\n",
    "    )\n",
    "    # Create a new column based on converting the thresholds to dummy numbers. Values given are 1, if displacement < encounter threshold, 0.5, if encounter threshold < disp < away threshold and 0 if disp > away threshold.\n",
    "    # Due to the linear interpolation there are no np.nans\n",
    "    displacement_dataset.loc[:, [\"enc_dummy\"]] = pd.cut(\n",
    "        displacement_dataset.disp,\n",
    "        [0, encounter_threshold, away_threshold, np.inf],\n",
    "        labels=[1, 0.5, 0],\n",
    "    )\n",
    "    # Convert datatype to float from category (due to pd.cut) for downstream functions\n",
    "    displacement_dataset = displacement_dataset.astype({\"enc_dummy\": float})\n",
    "    # Check if 1 is present at least once in the dataset. If not create a dataframe with 0 values to return\n",
    "    if 1 not in displacement_dataset.enc_dummy.values:\n",
    "        enc_df = pd.DataFrame(data=[[0, np.nan, 0.0, 0, 0.0]])\n",
    "        enc_df.columns = [\n",
    "            \"enc_number\",\n",
    "            \"enc_start_time\",\n",
    "            \"enc_duration\",\n",
    "            \"enc_sequences\",\n",
    "            \"enc_sequences_duration\",\n",
    "        ]\n",
    "        return enc_df\n",
    "    # Identify index values where enc_dummy is 0 i.e., displacement is > away threshold\n",
    "    away_indices = displacement_dataset[\n",
    "        displacement_dataset[\"enc_dummy\"] == 0\n",
    "    ].index.values\n",
    "    # Check if there is none or only 1 index with enc_dummy=0\n",
    "    if away_indices.size < 2:\n",
    "        enc_df = pd.DataFrame(data=[[0, np.nan, 0.0, 0, 0.0]])\n",
    "        enc_df.columns = [\n",
    "            \"enc_number\",\n",
    "            \"enc_start_time\",\n",
    "            \"enc_duration\",\n",
    "            \"enc_sequences\",\n",
    "            \"enc_sequences_duration\",\n",
    "        ]\n",
    "        return enc_df\n",
    "    # Check if first value is not starting index and insert it if not\n",
    "    if away_indices[0] != np.take(displacement_dataset.index.values, 0):\n",
    "        away_indices = np.insert(\n",
    "            away_indices, 0, np.take(displacement_dataset.index.values, 0)\n",
    "        )  # Insert starting value of index range\n",
    "    # Get pairs of consecutive indices\n",
    "    away_indices_pair = list(zip(away_indices, away_indices[1:]))\n",
    "    # Get values between the consecutive indices with value of 1\n",
    "    seq_bw_away = [\n",
    "        displacement_dataset.loc[x + 1 : y - 1, \"enc_dummy\"]\n",
    "        for (x, y) in away_indices_pair\n",
    "    ]\n",
    "    # Remove list elements which have only 1 index value\n",
    "    seq_bw_away_sub = [x for x in seq_bw_away if x.size > 1]\n",
    "    # Subset list elements which have at least 1 value of 1\n",
    "    # This list of lists will be used for all subsequent calculations\n",
    "    enc_seq = [x for x in seq_bw_away_sub if np.in1d(1, x)]\n",
    "\n",
    "    # Calculate overall encounter duration as time from when an individual crosses threshold (enc_dummy=1) to when it crosses away threshold again (enc_dummy=0)\n",
    "    # Get index values where 1 is present for first time in each list within encounter sequences.\n",
    "    # Then use this to obtain the start times of the encounters\n",
    "    enc_start_times = [\n",
    "        displacement_dataset.loc[x.index.values[np.where(x == 1)[0][0]], \"Time\"]\n",
    "        for x in enc_seq\n",
    "    ]\n",
    "    # Get index values of last time point in each encounter.\n",
    "    # Then use this to obtain the end times of the whole encounters\n",
    "    enc_end_times = [\n",
    "        displacement_dataset.loc[x.index.values[-1], \"Time\"] for x in enc_seq\n",
    "    ]\n",
    "    # Subtract end and start times element wise and convert to seconds\n",
    "    enc_time = np.subtract(enc_end_times, enc_start_times)\n",
    "    enc_time_sec = [x.total_seconds() for x in enc_time]\n",
    "\n",
    "    # Calculate number of instances within each encounter where the individual is within encounter threshold for a sequential period of time and the total duration of these instances\n",
    "    # This is based on extracting all consecutive sequences where enc_dummy=1 and calculating the start and end time of these sequences\n",
    "    # The function `time_within_encounter_threshold` runs over each encounter sequence to extract the sub-sequences\n",
    "    enc_sub_seq = [\n",
    "        time_within_encounter_threshold(displacement_dataset, x) for x in enc_seq\n",
    "    ]\n",
    "    enc_sub_seq_num = [x for x, y in enc_sub_seq]\n",
    "    enc_sub_seq_time = [y for x, y in enc_sub_seq]\n",
    "\n",
    "    # Create a dataframe combining all the paeameters\n",
    "    # First calculate number of encounters\n",
    "    enc_num = np.arange(1, len(enc_seq) + 1)\n",
    "    # Create a dataframe\n",
    "    enc_df = pd.DataFrame(\n",
    "        data=[enc_num, enc_start_times, enc_time_sec, enc_sub_seq_num, enc_sub_seq_time]\n",
    "    )\n",
    "    # transpose dataframe\n",
    "    enc_df = enc_df.T\n",
    "    # Add column names\n",
    "    enc_df.columns = [\n",
    "        \"enc_number\",\n",
    "        \"enc_start_time\",\n",
    "        \"enc_duration\",\n",
    "        \"enc_sequences\",\n",
    "        \"enc_sequences_duration\",\n",
    "    ]\n",
    "    enc_df = enc_df.astype(\n",
    "        {\n",
    "            \"enc_number\": int,\n",
    "            \"enc_duration\": float,\n",
    "            \"enc_sequences\": int,\n",
    "            \"enc_sequences_duration\": float,\n",
    "        }\n",
    "    )\n",
    "    return enc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate encounter durations between specific ants\n",
    "\n",
    "This function combines obtaining all the trajectories from the `trajectory_output_all` function, then rearranges this to obtain the displacement between the focal ant and all other ants at each time point (in this every second, since the trajectories are summarised to the nearest second by averaging the X and Y coordinate for each second). This dataset is then grouped by focalID and antID and then the `encounter_duration` function is run over these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def focal_encounters(\n",
    "    start_time, end_time, exp, focal_ID, exp_day, encounter_threshold, away_threshold\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to obtain trajectories for focal and caregiver antIDs, merge by time and calculate displacement of each caregiver ID from the focal ID at every second\n",
    "    :param start_time: Starting time to obtain trajectories from. Passed on to function trajectory_output\n",
    "    :param end_time: Ending time to obtain trajectories from. Passed on to function trajectory_output\n",
    "    :param exp: Location of myrmidon file\n",
    "    :param focal_ID: Injured AntID\n",
    "    :param exp_day: Day of the experiment. This is added to the dataframe for identification\n",
    "    :param encounter_threshold: Threshold displacement to use as encounter\n",
    "    :param away_threshold: Threshold displacement to use as the start/end of an encounter\n",
    "    :return: Returns a datafarme containing the Time (in bins of 1s based on function trajectory_output), the focal and caregiver ID, the space in which the focal and caregiver ants are present, and the displacement between them (calculated as np.nan if they are in different spaces. In a CSV output this will be converted to a blank entry).\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    # # Focal Ant matcher\n",
    "    # focal_matcher = fm.Matcher.AntID(focal_ID)\n",
    "    # # Caregiver individual matchers\n",
    "    # # others = [fm.Matcher.AntID(x) for x in other_IDs]\n",
    "    # # Create single matcher object by unpacking the list within an Or Matcher\n",
    "    # #others_matcher = fm.Matcher.Or(*others)\n",
    "    # # Focal Ant trajectory\n",
    "    # focal_traj = trajectory_output(start_time, end_time, exp, focal_matcher)\n",
    "    # All ant trajectories\n",
    "    other_traj = trajectory_output_all(start_time, end_time, exp)\n",
    "    # Focal ant trajectory\n",
    "    focal_traj = other_traj[other_traj[\"AntID\"] == focal_ID]\n",
    "    # Sort Time column for both dataframes\n",
    "    other_traj = other_traj.sort_values(\"Time\")\n",
    "    focal_traj = focal_traj.sort_values(\"Time\")\n",
    "\n",
    "    # If focal trajectory is an empty dataframe, create a dataframe with na values for encounter parameters\n",
    "    if focal_traj.empty:\n",
    "        full_traj = other_traj.rename(columns={\"Space\": \"Space_ant\"})\n",
    "        full_traj[\"focalID\"] = focal_ID\n",
    "        full_traj[\"Space_focal\"] = full_traj[\"disp\"] = (\n",
    "            np.nan\n",
    "        )  # Create columns with na values\n",
    "        full_traj = full_traj[\n",
    "            [\"Time\", \"focalID\", \"AntID\", \"disp\", \"Space_focal\", \"Space_ant\"]\n",
    "        ]\n",
    "        full_traj[\"exp_day\"] = exp_day\n",
    "        full_traj = full_traj[full_traj[\"focalID\"] != full_traj[\"AntID\"]].reset_index()\n",
    "        # Group data frame, create columns with na and output encounter dataframe\n",
    "        enc_df = (\n",
    "            full_traj.groupby([\"exp_day\", \"focalID\", \"AntID\"])\n",
    "            .apply(lambda x: pd.Series([np.nan] * 5))\n",
    "            .reset_index()\n",
    "            .rename(\n",
    "                columns={\n",
    "                    0: \"enc_number\",\n",
    "                    1: \"enc_start_time\",\n",
    "                    2: \"enc_duration\",\n",
    "                    3: \"enc_sequences\",\n",
    "                    4: \"enc_sequences_duration\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            f\"{'Focal ID trajectory is empty for list item '}{exp_day}{' .Returning dataframe with no displacement and encounters calculated'}\"\n",
    "        )\n",
    "        return enc_df\n",
    "    # If trajectory of all other individuals is an empty dataframe, create a dataframe with na values for encounter parameters\n",
    "    if other_traj.empty:\n",
    "        full_traj = focal_traj.rename(\n",
    "            columns={\"AntID\": \"focalID\", \"Space\": \"Space_focal\"}\n",
    "        )\n",
    "        full_traj[\"AntID\"] = full_traj[\"Space_ant\"] = full_traj[\"disp\"] = (\n",
    "            np.nan\n",
    "        )  # Create columns with na values\n",
    "        full_traj = full_traj[\n",
    "            [\"Time\", \"focalID\", \"AntID\", \"disp\", \"Space_focal\", \"Space_ant\"]\n",
    "        ]\n",
    "        full_traj[\"exp_day\"] = exp_day\n",
    "        # Group data frame, create columns with na and output encounter dataframe\n",
    "        enc_df = (\n",
    "            full_traj.groupby([\"exp_day\", \"focalID\", \"AntID\"])\n",
    "            .apply(lambda x: pd.Series([np.nan] * 5))\n",
    "            .reset_index()\n",
    "            .rename(\n",
    "                columns={\n",
    "                    0: \"enc_number\",\n",
    "                    1: \"enc_start_time\",\n",
    "                    2: \"enc_duration\",\n",
    "                    3: \"enc_sequences\",\n",
    "                    4: \"enc_sequences_duration\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            f\"{'Caregiver ID trajectories are empty for list item '}{exp_day}{' .Returning dataframe with no displacement and encounters calculated'}\"\n",
    "        )\n",
    "        return enc_df\n",
    "\n",
    "    # Merge focal and caregiver trajectories on Time column using merge_asof to match nearest time values\n",
    "    full_traj = pd.merge_asof(\n",
    "        other_traj,\n",
    "        focal_traj,\n",
    "        on=\"Time\",\n",
    "        suffixes=(\"_ant\", \"_focal\"),\n",
    "        direction=\"nearest\",\n",
    "        tolerance=pd.Timedelta(\"1s\"),\n",
    "    )\n",
    "    # Obtain X coordinate and Y coordinate difference between Focal and Caregivers, for each row\n",
    "    full_traj[\"X_diff\"] = full_traj[\"X_coor_focal\"] - full_traj[\"X_coor_ant\"]\n",
    "    full_traj[\"Y_diff\"] = full_traj[\"Y_coor_focal\"] - full_traj[\"Y_coor_ant\"]\n",
    "    # Obtain displacement\n",
    "    full_traj[\"disp\"] = np.linalg.norm(\n",
    "        full_traj[[\"X_diff\", \"Y_diff\"]].to_numpy(), axis=1\n",
    "    )\n",
    "    # Rename columns\n",
    "    full_traj = full_traj.rename(\n",
    "        columns={\"AntID_focal\": \"focalID\", \"AntID_ant\": \"AntID\"}\n",
    "    )\n",
    "    # Subset specific columns\n",
    "    full_traj = full_traj[\n",
    "        [\"Time\", \"focalID\", \"AntID\", \"disp\", \"Space_focal\", \"Space_ant\"]\n",
    "    ]\n",
    "    # Add experimental day\n",
    "    full_traj[\"exp_day\"] = exp_day\n",
    "    # Remove instances where the focal ant's displacement is calculated wrt itself.\n",
    "    full_traj = full_traj[full_traj[\"focalID\"] != full_traj[\"AntID\"]].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    # Replace with arbitrary high value of displacemeent if focal ant and caregiver are in different spaces. Use notnull to filter out instances where focal or caregiver space is not known. The higgh value will ensure that this case is always considered as > away_threshold in count_encounters function\n",
    "    full_traj.loc[\n",
    "        (\n",
    "            (full_traj.Space_focal.notnull())\n",
    "            & (full_traj.Space_ant.notnull())\n",
    "            & (full_traj.Space_focal != full_traj.Space_ant)\n",
    "        ),\n",
    "        \"disp\",\n",
    "    ] = 100000\n",
    "    # Apply encounter_duration function over grouped dataframe, reset index and rename columns\n",
    "    enc_df = (\n",
    "        full_traj.groupby([\"exp_day\", \"focalID\", \"AntID\"])\n",
    "        .apply(lambda x: encounter_duration(x, encounter_threshold, away_threshold))\n",
    "        .reset_index()\n",
    "        .drop(\"level_3\", axis=1)\n",
    "    )\n",
    "    end = datetime.now()\n",
    "    print(\n",
    "        f\"{'Encounters for experimental day '}{exp_day}{' calculated in '}{end - start}\"\n",
    "    )\n",
    "    return enc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to run encounter calculations over multiple phases of one experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_encounters_cluster(exp_list, control_list, pre_list, post_list, colonyID):\n",
    "    \"\"\"\n",
    "    Helper function to run focal_caregivers_disp_exp and count_encounters over multiple lists associated with different phases for one colony\n",
    "    :param exp_list: List of start_time, end_time, exp, focalID, careggiverIDs and exp_day for Experimental phase\n",
    "    :param control_list: List for control phase\n",
    "    :param pre_list: List for pre-experimental phase\n",
    "    :param post_list: List for post-experimental phase\n",
    "    :param colonyID: colonyID corresponding to the myrmidon file\n",
    "    :return: Dataframe combining the encounters for each of the 4 phases for one colony\n",
    "    \"\"\"\n",
    "    print(\"Experimental phase\")\n",
    "    exp_enc = [\n",
    "        focal_encounters(\n",
    "            start, end, exp, focalID, exp_day, encounter_threshold, away_threshold\n",
    "        )\n",
    "        for start, end, exp, focalID, exp_day, encounter_threshold, away_threshold in exp_list\n",
    "    ]\n",
    "    exp_enc = pd.concat(exp_enc)\n",
    "    exp_enc[\"phase\"] = \"Exp\"\n",
    "    print(\"Control phase\")\n",
    "    control_enc = [\n",
    "        focal_encounters(\n",
    "            start, end, exp, focalID, exp_day, encounter_threshold, away_threshold\n",
    "        )\n",
    "        for start, end, exp, focalID, exp_day, encounter_threshold, away_threshold in control_list\n",
    "    ]\n",
    "    control_enc = pd.concat(control_enc)\n",
    "    control_enc[\"phase\"] = \"Control\"\n",
    "    print(\"Pre-Experimental phase\")\n",
    "    pre_enc = [\n",
    "        focal_encounters(\n",
    "            start, end, exp, focalID, exp_day, encounter_threshold, away_threshold\n",
    "        )\n",
    "        for start, end, exp, focalID, exp_day, encounter_threshold, away_threshold in pre_list\n",
    "    ]\n",
    "    pre_enc = pd.concat(pre_enc)\n",
    "    pre_enc[\"phase\"] = \"Pre\"\n",
    "    print(\"Post-Experimental phase\")\n",
    "    post_enc = [\n",
    "        focal_encounters(\n",
    "            start, end, exp, focalID, exp_day, encounter_threshold, away_threshold\n",
    "        )\n",
    "        for start, end, exp, focalID, exp_day, encounter_threshold, away_threshold in post_list\n",
    "    ]\n",
    "    post_enc = pd.concat(post_enc)\n",
    "    post_enc[\"phase\"] = \"Post\"\n",
    "    # Combine encounter dataframes\n",
    "    enc_list = [exp_enc, control_enc, pre_enc, post_enc]\n",
    "    enc = pd.concat(enc_list)\n",
    "    # Add colonyID\n",
    "    enc[\"colony\"] = colonyID\n",
    "    # Sort by values\n",
    "    enc = enc.sort_values(\n",
    "        by=[\"colony\", \"phase\", \"exp_day\", \"focalID\", \"AntID\"]\n",
    "    ).reset_index(drop=True)\n",
    "    enc = enc[\n",
    "        [\n",
    "            \"colony\",\n",
    "            \"phase\",\n",
    "            \"exp_day\",\n",
    "            \"focalID\",\n",
    "            \"AntID\",\n",
    "            \"enc_number\",\n",
    "            \"enc_start_time\",\n",
    "            \"enc_duration\",\n",
    "            \"enc_sequences\",\n",
    "            \"enc_sequences_duration\",\n",
    "        ]\n",
    "    ]\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Injury Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds\n",
    "encounter_threshold = 300  # threshold for counting as an encounter\n",
    "away_threshold = 1000  # Threshold for counting as the end of an encounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Colony Cfel 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_myrmidon = \"/media/ebiag/Ebi-2/Woundcare Experiment1/Cfell_wound_col42.myrmidon\"\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "# Create list of focal ants\n",
    "focal = [106, 63, 23, 53, 19]\n",
    "# Experimental phase\n",
    "day_starts_exp = [\n",
    "    datetime(2022, 5, 2, 16, 3).astimezone(tz=None),\n",
    "    datetime(2022, 5, 3, 15, 53).astimezone(tz=None),\n",
    "    datetime(2022, 5, 4, 15, 50).astimezone(tz=None),\n",
    "    datetime(2022, 5, 5, 15, 50).astimezone(tz=None),\n",
    "    datetime(2022, 5, 6, 15, 55).astimezone(tz=None),\n",
    "]\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "exp_days = [1, 2, 3, 4, 5]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control Phase\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2022, 5, 1, 15, 54).astimezone(tz=None), 5)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre experimental phase\n",
    "day_starts_pre = [\n",
    "    datetime(2022, 5, 2, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 3, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 4, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 5, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 6, 9, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase\n",
    "day_starts_post = [\n",
    "    datetime(2022, 5, 3, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 4, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 5, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 6, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 7, 9, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel42_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel42\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel42_enc.to_csv(\"Cfel42_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Colony Cfel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_myrmidon = \"/media/ebiag/Ebi-2/Woundcare Experiment2/woundcare_cfell1_T2.myrmidon\"\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "# Focal Ants\n",
    "focal = [87, 37, 58, 38, 3]\n",
    "exp_days = [1, 2, 3, 4, 5]\n",
    "# Experimental Phase list\n",
    "day_starts_exp = [\n",
    "    datetime(2022, 6, 5, 14, 57).astimezone(tz=None),\n",
    "    datetime(2022, 6, 6, 14, 30).astimezone(tz=None),\n",
    "    datetime(2022, 6, 7, 14, 49).astimezone(tz=None),\n",
    "    datetime(2022, 6, 8, 14, 43).astimezone(tz=None),\n",
    "    datetime(2022, 6, 9, 15, 5).astimezone(tz=None),\n",
    "]\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control phase list\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2022, 6, 4, 14, 48).astimezone(tz=None), 5)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre Experimental phase list\n",
    "day_starts_pre = [\n",
    "    datetime(2022, 6, 5, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 6, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 7, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 8, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 9, 8, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase list\n",
    "day_starts_post = [\n",
    "    datetime(2022, 6, 6, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 7, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 8, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 9, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 10, 8, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel1_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel1_enc.to_csv(\"Cfel1_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Colony Cfel 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_myrmidon = \"/media/ebiag/Ebi-2/Woundcare Experiment3/woundcare_cfell54_T3.myrmidon\"\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "# Focal Ants\n",
    "focal = [108, 114, 62, 12]\n",
    "exp_days = [1, 2, 3, 4]\n",
    "# Experimental Phase list\n",
    "day_starts_exp = [\n",
    "    datetime(2022, 6, 20, 14, 35).astimezone(tz=None),\n",
    "    datetime(2022, 6, 21, 14, 21).astimezone(tz=None),\n",
    "    datetime(2022, 6, 22, 14, 28).astimezone(tz=None),\n",
    "    datetime(2022, 6, 23, 14, 14).astimezone(tz=None),\n",
    "]\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control phase list\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2022, 6, 19, 14, 25).astimezone(tz=None), 4)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre Experimental phase list\n",
    "day_starts_pre = [\n",
    "    datetime(2022, 6, 20, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 21, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 22, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 23, 8, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase list\n",
    "day_starts_post = [\n",
    "    datetime(2022, 6, 21, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 22, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 23, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 24, 8, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel54_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel54\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel54_enc.to_csv(\"Cfel54_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infection Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colony Cfel 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_myrmidon = \"/media/ebiag/Ebi-3/InfectionExp_Cfel13/InfectionExp_Cfel13.myrmidon\"\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "# Focal Ants\n",
    "focal = [9, 82, 40, 7, 55, 80, 26, 22, 27, 98]\n",
    "exp_days = [1, 2, 3, 4, 5] * 2\n",
    "# Experimental Phase list\n",
    "day_starts_exp = [\n",
    "    datetime(2023, 4, 24, 15, 29).astimezone(tz=None),\n",
    "    datetime(2023, 4, 25, 14, 19).astimezone(tz=None),\n",
    "    datetime(2023, 4, 26, 15, 3).astimezone(tz=None),\n",
    "    datetime(2023, 4, 27, 16, 43).astimezone(tz=None),\n",
    "    datetime(2023, 4, 28, 14, 27).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control phase list\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2023, 4, 23, 15, 5).astimezone(tz=None), 10)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre Experimental phase list\n",
    "day_starts_pre = [\n",
    "    datetime(2023, 4, 24, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 25, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 26, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 27, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 28, 8, 0).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase list\n",
    "day_starts_post = [\n",
    "    datetime(2023, 4, 25, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 26, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 27, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 28, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 29, 8, 0).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfel13_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel13\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfel13_enc.to_csv(\"Cfel13_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colony Cfel 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_myrmidon = \"/media/ebiag/Ebi-3/InfectionExp_Cfel55/InfectionExpCol55.myrmidon\"\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "# Focal Ants\n",
    "focal = [30, 36, 44, 53, 55, 72, 15, 57, 67, 81]\n",
    "exp_days = [1, 2, 3, 4, 5] * 2\n",
    "# Experimental Phase list\n",
    "day_starts_exp = [\n",
    "    datetime(2023, 4, 20, 15, 45).astimezone(tz=None),\n",
    "    datetime(2023, 4, 21, 14, 48).astimezone(tz=None),\n",
    "    datetime(2023, 4, 22, 14, 17).astimezone(tz=None),\n",
    "    datetime(2023, 4, 23, 14, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 24, 14, 54).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control phase list\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2023, 4, 18, 14, 40).astimezone(tz=None), 10)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre Experimental phase list\n",
    "day_starts_pre = [\n",
    "    datetime(2023, 4, 20, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 21, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 22, 7, 30).astimezone(tz=None),\n",
    "    datetime(2023, 4, 23, 7, 30).astimezone(tz=None),\n",
    "    datetime(2023, 4, 24, 8, 0).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase list\n",
    "day_starts_post = [\n",
    "    datetime(2023, 4, 21, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 22, 7, 30).astimezone(tz=None),\n",
    "    datetime(2023, 4, 23, 7, 30).astimezone(tz=None),\n",
    "    datetime(2023, 4, 24, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 4, 25, 8, 0).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfel55_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel55\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfel55_enc.to_csv(\"Cfel55_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colony Cfel 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_myrmidon = \"/media/ebiag/Ebi-1/InfectionExp_Cfel64/InfectionExpCol64.myrmidon\"\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "# Focal Ants\n",
    "focal = [6, 104, 115, 78, 59, 32, 86, 1, 38, 3]\n",
    "exp_days = [1, 2, 3, 4, 5] * 2\n",
    "# Experimental Phase list\n",
    "day_starts_exp = [\n",
    "    datetime(2023, 6, 1, 15, 51).astimezone(tz=None),\n",
    "    datetime(2023, 6, 2, 14, 44).astimezone(tz=None),\n",
    "    datetime(2023, 6, 3, 14, 50).astimezone(tz=None),\n",
    "    datetime(2023, 6, 4, 14, 43).astimezone(tz=None),\n",
    "    datetime(2023, 6, 5, 14, 52).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control phase list\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2023, 5, 31, 15, 5).astimezone(tz=None), 10)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre Experimental phase list\n",
    "day_starts_pre = [\n",
    "    datetime(2023, 6, 1, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 6, 2, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 6, 3, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 6, 4, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 6, 5, 8, 0).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase list\n",
    "day_starts_post = [\n",
    "    datetime(2023, 6, 2, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 6, 3, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 6, 4, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 6, 5, 8, 0).astimezone(tz=None),\n",
    "    datetime(2023, 6, 6, 8, 0).astimezone(tz=None),\n",
    "] * 2\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfel64_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel64\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfel64_enc.to_csv(\"Cfel64_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
