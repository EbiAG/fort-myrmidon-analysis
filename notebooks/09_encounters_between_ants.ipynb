{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encounters between ants\n",
    "Function to calculate the encounters between specific ants (e.g., focal and caregiver ants) from a ```.mymridon``` experiment file. <br><br>\n",
    "There is probably an easier way to do this by querying individual frames directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta  # For convenient handling of time and date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  # Used to create a dataframe, similar to the structure used in R\n",
    "import py_fort_myrmidon as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to output trajectories of all ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trajectory_output_all(start_time, end_time, exp):\n",
    "    \"\"\"\n",
    "    Function to extract daily trajectories as a parquet file, grouped by AntID. While it is setup to extract daily trajectories, it can work for any arbitrary time duration\n",
    "    :param start_time: The start datetime object. this will be converted to a fort-myrmidon Time object\n",
    "    :param end_time: The end datetime object. this will be converted to a fort-myrmidon Time object\n",
    "    :param exp: The name of the experiment i.e., the myrmidon file\n",
    "    :param matcher_query: The fm matcher corresponding to the focal IDs\n",
    "    :return: Outputs a pandas dataframe containing AntID, Space, Time, X_coordinates and Y_coordinates of each ID averaged over 1 second from the X and Y coordinates. Averagingg is done to have a dataset which can be merged across IDs using at the resolution of 1s.\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    t_begin = fm.Time(start_time)\n",
    "    t_stop = fm.Time(end_time)\n",
    "    trajectory = fm.Query.ComputeAntTrajectories(\n",
    "        experiment=exp,\n",
    "        start=t_begin,\n",
    "        end=t_stop,\n",
    "        # matcher=matcher_query,\n",
    "        maximumGap=fm.Duration.Parse(\"1000h\"),\n",
    "        reportProgress=False,\n",
    "    )\n",
    "    # Make a list of lists with trajectory values needed. Position is an array of 5 columns, so specific columns are called\n",
    "    traj_list = [\n",
    "        [\n",
    "            trajectory.Ant,\n",
    "            trajectory.Space,\n",
    "            trajectory.Start.ToDateTime(),\n",
    "            trajectory.Positions[:, 0],\n",
    "            trajectory.Positions[:, 1],\n",
    "            trajectory.Positions[:, 2],\n",
    "        ]\n",
    "        for trajectory in trajectory\n",
    "    ]\n",
    "    # Make the list into a dataframe\n",
    "    traj_df = pd.DataFrame(\n",
    "        traj_list,\n",
    "        columns=[\"AntID\", \"Space\", \"StartTime\", \"Pos_time\", \"X_coor\", \"Y_coor\"],\n",
    "    )\n",
    "    # Explode columns which are in the form of lists to expand the dataframe\n",
    "    traj_df = traj_df.explode(column=[\"Pos_time\", \"X_coor\", \"Y_coor\"])\n",
    "    # Coerce coordinates to integer\n",
    "    traj_df[\"X_coor\"] = pd.to_numeric(traj_df[\"X_coor\"], errors=\"coerce\")\n",
    "    traj_df[\"Y_coor\"] = pd.to_numeric(traj_df[\"Y_coor\"], errors=\"coerce\")\n",
    "    # Convert Pos_time to timedelta and obtain actual datetime for each trajectory entry\n",
    "    traj_df[\"Pos_time\"] = pd.to_numeric(traj_df[\"Pos_time\"], errors=\"coerce\")\n",
    "    traj_df[\"Pos_time\"] = pd.to_timedelta(\n",
    "        traj_df[\"Pos_time\"], unit=\"S\", errors=\"coerce\"\n",
    "    )\n",
    "    traj_df[\"Time\"] = traj_df[\"StartTime\"] + traj_df[\"Pos_time\"]\n",
    "    # Drop unwanted ccolumns\n",
    "    traj_df = traj_df.drop([\"StartTime\", \"Pos_time\"], axis=1)\n",
    "    # Reorder columns\n",
    "    traj_df = traj_df[[\"AntID\", \"Space\", \"Time\", \"X_coor\", \"Y_coor\"]]\n",
    "    if traj_df.empty:  # If no trajectories are output\n",
    "        # empty_row = pd.DataFrame([{'AntID': 'Unknown', 'Space':np.nan, 'Time':np.nan, 'X_coor':np.nan, 'Y_coor':np.nan}]) # Create empty row with unknown as antID\n",
    "        # traj_df = pd.concat([empty_row]) # Add empty row to dataframe\n",
    "        print(\"No trajectories found. Created empty dataframe\")\n",
    "        return traj_df  # Return empty dataframe\n",
    "    # Obtain average X and Y coordinates per second\n",
    "    traj_df = (\n",
    "        traj_df.groupby([pd.Grouper(key=\"Time\", freq=\"1s\"), \"AntID\", \"Space\"])\n",
    "        .agg(X_mean=(\"X_coor\", \"mean\"), Y_mean=(\"Y_coor\", \"mean\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    end = datetime.now()\n",
    "    # print(\"Trajectories output in\", end-start)\n",
    "    return traj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to count encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_encounters(displacement_dataset, encounter_threshold, away_threshold):\n",
    "    \"\"\"\n",
    "    Function to calculate number of encounters between caregivers and focal ants. Function should be run only on datasets which contain displacement data from one pair of caregiver and focalID, since it is based on the index values. Either a subset dataset obtained from focal_caregivers_disp_exp can be used, or the function can be applied after grouping by specific variables in a larger dataframe\n",
    "    :param displacement_dataset: The displacement dataset; either a subset obtained from focal_caregivers_disp_exp or a pandas grouped by dataset\n",
    "    :param encounter_threshold: Threshold displacement to use as encounter\n",
    "    :param away_threshold: Threshold displacement to use as the start/end of an encounter\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Recreate displacement to include values across different spaces (since we need it to not be np.nan to distinguish it from actual unknown values)\n",
    "\n",
    "    # Create a new column based on converting the thresholds to dummy numbers. Values given are 1, if displacement < encounter threshold, 0.5, if encounter threshold < disp < away threshold and 0 if disp > away threshold. np.nans are retained\n",
    "    displacement_dataset[\"enc_comb\"] = pd.cut(\n",
    "        displacement_dataset.disp,\n",
    "        [0, encounter_threshold, away_threshold, np.inf],\n",
    "        labels=[1, 0.5, 0],\n",
    "    )\n",
    "    # Convert datatype to float from category (due to pd.cut) for downstream functions\n",
    "    displacement_dataset = displacement_dataset.astype({\"enc_comb\": float})\n",
    "\n",
    "    if (\n",
    "        displacement_dataset.enc_comb.isnull().all()\n",
    "    ):  # Check if all values in enc_comb are NA\n",
    "        print(\"No displacement data available\")\n",
    "        encounters = \"NA\"  # If enc_comb has only na values, make encounters = NA\n",
    "        return encounters\n",
    "    enc_ind = displacement_dataset[displacement_dataset[\"enc_comb\"] == 1].index.values\n",
    "    if enc_ind.size == 0:  # Check if the number of instances of 1 in enc_comb is 0\n",
    "        encounters = 0  # If enc_comb has no 1 value, make encounters = 0 and exit\n",
    "        return encounters\n",
    "\n",
    "    # print(f\"{'exp_day is'}{displacement_dataset.exp_day.unique()}{'and caregiverID is'}{displacement_dataset.caregiverID.unique()}\")\n",
    "    if enc_ind[0] != np.take(\n",
    "        displacement_dataset.index.values, 0\n",
    "    ):  # Check if first value is not starting index\n",
    "        enc_ind = np.insert(\n",
    "            enc_ind, 0, np.take(displacement_dataset.index.values, 0)\n",
    "        )  # Insert starting value of index range\n",
    "    enc_ind_pair = list(zip(enc_ind, enc_ind[1:]))  # Get pairs of consecutive indices\n",
    "    enc_comb_list = [\n",
    "        displacement_dataset.loc[x + 1 : y - 1, \"enc_comb\"] for (x, y) in enc_ind_pair\n",
    "    ]  # Get values between the consecutive indices with value of 1\n",
    "    list_filter = [\n",
    "        np.logical_not(x.size < 2) for x in enc_comb_list\n",
    "    ]  # Get Boolean list of where the individual list size is greater than 2\n",
    "    enc_comb_sub = [\n",
    "        enc_comb_list[i] for i in range(len(enc_comb_list)) if list_filter[i]\n",
    "    ]  # Use the boolean list to filter the original list\n",
    "    enc_comb_list_nona = [\n",
    "        x[np.logical_not(np.isnan(x))] for x in enc_comb_sub\n",
    "    ]  # Remove nas from the list\n",
    "    enc_comb_zero = [\n",
    "        np.any(x) for x in enc_comb_list_nona\n",
    "    ]  # Get True if any element in the list is 0\n",
    "    encounters = sum(enc_comb_zero)  # Get summation of number of elements with 0\n",
    "    return encounters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to count encounters of specific ants\n",
    "\n",
    "This function combines obtaining all the trajectories from the `trajectory_output_all` function, then rearranges this to obtain the displacement between the focal ant and all other ants at each time point (in this every second, since the trajectories are summarised to the nearest second by averaging the X and Y coordinate for each second). This dataset is then grouped by focalID and antID and then the number of encounters between these 2 IDs are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def focal_encounters(\n",
    "    start_time, end_time, exp, focal_ID, exp_day, encounter_threshold, away_threshold\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to obtain trajectories for focal and caregiver antIDs, merge by time and calculate displacement of each caregiver ID from the focal ID at every second\n",
    "    :param start_time: Starting time to obtain trajectories from. Passed on to function trajectory_output\n",
    "    :param end_time: Ending time to obtain trajectories from. Passed on to function trajectory_output\n",
    "    :param exp: Location of myrmidon file\n",
    "    :param focal_ID: Injured AntID\n",
    "    :param exp_day: Day of the experiment. This is added to the dataframe for identification\n",
    "    :param encounter_threshold: Threshold displacement to use as encounter\n",
    "    :param away_threshold: Threshold displacement to use as the start/end of an encounter\n",
    "    :return: Returns a datafarme containing the Time (in bins of 1s based on function trajectory_output), the focal and caregiver ID, the space in which the focal and caregiver ants are present, and the displacement between them (calculated as np.nan if they are in different spaces. In a CSV output this will be converted to a blank entry).\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    # # Focal Ant matcher\n",
    "    # focal_matcher = fm.Matcher.AntID(focal_ID)\n",
    "    # # Caregiver individual matchers\n",
    "    # # others = [fm.Matcher.AntID(x) for x in other_IDs]\n",
    "    # # Create single matcher object by unpacking the list within an Or Matcher\n",
    "    # #others_matcher = fm.Matcher.Or(*others)\n",
    "    # # Focal Ant trajectory\n",
    "    # focal_traj = trajectory_output(start_time, end_time, exp, focal_matcher)\n",
    "    # All ant trajectories\n",
    "    other_traj = trajectory_output_all(start_time, end_time, exp)\n",
    "    # Focal ant trajectory\n",
    "    focal_traj = other_traj[other_traj[\"AntID\"] == focal_ID]\n",
    "    # Merge focal and caregiver trajectories on Time column\n",
    "    if focal_traj.empty:  # If focal trajectory is an empty dataframe\n",
    "        full_traj = other_traj.rename(columns={\"Space\": \"Space_ant\"})\n",
    "        full_traj[\"focalID\"] = focal_ID\n",
    "        full_traj[\"Space_focal\"] = full_traj[\"disp\"] = (\n",
    "            np.nan\n",
    "        )  # Create columns with na values\n",
    "        full_traj = full_traj[\n",
    "            [\"Time\", \"focalID\", \"AntID\", \"disp\", \"Space_focal\", \"Space_ant\"]\n",
    "        ]\n",
    "        full_traj[\"exp_day\"] = exp_day\n",
    "        full_traj = full_traj[full_traj[\"focalID\"] != full_traj[\"AntID\"]].reset_index()\n",
    "        enc = (\n",
    "            full_traj.groupby([\"exp_day\", \"focalID\", \"AntID\"])\n",
    "            .apply(lambda x: \"NA\")\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"encounters\"})\n",
    "        )  # Apply count_encounters function over grouped dataframe, reset index and rename columns\n",
    "        print(\n",
    "            f\"{'Focal ID trajectory is empty for list item '}{exp_day}{' .Returning dataframe with no displacement and encounters calculated'}\"\n",
    "        )\n",
    "        return enc\n",
    "    if other_traj.empty:  # If caregivers trajectory is an empty dataframe\n",
    "        full_traj = focal_traj.rename(\n",
    "            columns={\"AntID\": \"focalID\", \"Space\": \"Space_focal\"}\n",
    "        )\n",
    "        full_traj[\"AntID\"] = full_traj[\"Space_ant\"] = full_traj[\"disp\"] = (\n",
    "            np.nan\n",
    "        )  # Create columns with na values\n",
    "        full_traj = full_traj[\n",
    "            [\"Time\", \"focalID\", \"AntID\", \"disp\", \"Space_focal\", \"Space_ant\"]\n",
    "        ]\n",
    "        full_traj[\"exp_day\"] = exp_day\n",
    "        enc = (\n",
    "            full_traj.groupby([\"exp_day\", \"focalID\", \"AntID\"])\n",
    "            .apply(lambda x: \"NA\")\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"encounters\"})\n",
    "        )  # Apply count_encounters function over grouped dataframe, reset index and rename columns\n",
    "        print(\n",
    "            f\"{'Caregiver ID trajectories are empty for list item '}{exp_day}{' .Returning dataframe with no displacement and encounters calculated'}\"\n",
    "        )\n",
    "        return enc\n",
    "    full_traj = pd.merge(\n",
    "        other_traj, focal_traj, how=\"outer\", on=\"Time\", suffixes=(\"_ant\", \"_focal\")\n",
    "    )\n",
    "    # Obtain X coordinate and Y coordinate difference between Focal and Caregivers, for each row\n",
    "    full_traj[\"X_diff\"] = full_traj[\"X_mean_focal\"] - full_traj[\"X_mean_ant\"]\n",
    "    full_traj[\"Y_diff\"] = full_traj[\"Y_mean_focal\"] - full_traj[\"Y_mean_ant\"]\n",
    "    # Obtain displacement\n",
    "    full_traj[\"disp\"] = np.linalg.norm(\n",
    "        full_traj[[\"X_diff\", \"Y_diff\"]].to_numpy(), axis=1\n",
    "    )\n",
    "    full_traj = full_traj.rename(\n",
    "        columns={\"AntID_focal\": \"focalID\", \"AntID_ant\": \"AntID\"}\n",
    "    )\n",
    "    full_traj = full_traj[\n",
    "        [\"Time\", \"focalID\", \"AntID\", \"disp\", \"Space_focal\", \"Space_ant\"]\n",
    "    ]\n",
    "    full_traj[\"exp_day\"] = exp_day\n",
    "    # Remove instances where the focal ant's displacement is calculated wrt itself.\n",
    "    full_traj = full_traj[full_traj[\"focalID\"] != full_traj[\"AntID\"]].reset_index()\n",
    "    # Replace with arbitrary high value of displacemeent if focal ant and caregiver are in different spaces. Use notnull to filter out instances where focal or caregiver space is not known. The higgh value will ensure that this case is always considered as > away_threshold in count_encounters function\n",
    "    full_traj.loc[\n",
    "        (\n",
    "            (full_traj.Space_focal.notnull())\n",
    "            & (full_traj.Space_ant.notnull())\n",
    "            & (full_traj.Space_focal != full_traj.Space_ant)\n",
    "        ),\n",
    "        \"disp\",\n",
    "    ] = 100000\n",
    "    enc = (\n",
    "        full_traj.groupby([\"exp_day\", \"focalID\", \"AntID\"])\n",
    "        .apply(lambda x: count_encounters(x, encounter_threshold, away_threshold))\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"encounters\"})\n",
    "    )  # Apply count_encounters function over grouped dataframe, reset index and rename columns\n",
    "    end = datetime.now()\n",
    "    print(f\"{'Displacement for list item '}{exp_day}{' calculated in '}{end - start}\")\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to run encounter calculations over multiple phases of one experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_encounters_cluster(exp_list, control_list, pre_list, post_list, colonyID):\n",
    "    \"\"\"\n",
    "    Helper function to run focal_caregivers_disp_exp and count_encounters over multiple lists associated with different phases for one colony\n",
    "    :param exp_list: List of start_time, end_time, exp, focalID, careggiverIDs and exp_day for Experimental phase\n",
    "    :param control_list: List for control phase\n",
    "    :param pre_list: List for pre-experimental phase\n",
    "    :param post_list: List for post-experimental phase\n",
    "    :param colonyID: colonyID corresponding to the myrmidon file\n",
    "    :return: Dataframe combining the encounters for each of the 4 phases for one colony\n",
    "    \"\"\"\n",
    "    print(\"Experimental phase\")\n",
    "    exp_enc = [\n",
    "        focal_encounters(\n",
    "            start, end, exp, focalID, exp_day, encounter_threshold, away_threshold\n",
    "        )\n",
    "        for start, end, exp, focalID, exp_day, encounter_threshold, away_threshold in exp_list\n",
    "    ]\n",
    "    exp_enc = pd.concat(exp_enc)\n",
    "    exp_enc[\"phase\"] = \"Exp\"\n",
    "    print(\"Control phase\")\n",
    "    control_enc = [\n",
    "        focal_encounters(\n",
    "            start, end, exp, focalID, exp_day, encounter_threshold, away_threshold\n",
    "        )\n",
    "        for start, end, exp, focalID, exp_day, encounter_threshold, away_threshold in control_list\n",
    "    ]\n",
    "    control_enc = pd.concat(control_enc)\n",
    "    control_enc[\"phase\"] = \"Control\"\n",
    "    print(\"Pre-Experimental phase\")\n",
    "    pre_enc = [\n",
    "        focal_encounters(\n",
    "            start, end, exp, focalID, exp_day, encounter_threshold, away_threshold\n",
    "        )\n",
    "        for start, end, exp, focalID, exp_day, encounter_threshold, away_threshold in pre_list\n",
    "    ]\n",
    "    pre_enc = pd.concat(pre_enc)\n",
    "    pre_enc[\"phase\"] = \"Pre\"\n",
    "    print(\"Post-Experimental phase\")\n",
    "    post_enc = [\n",
    "        focal_encounters(\n",
    "            start, end, exp, focalID, exp_day, encounter_threshold, away_threshold\n",
    "        )\n",
    "        for start, end, exp, focalID, exp_day, encounter_threshold, away_threshold in post_list\n",
    "    ]\n",
    "    post_enc = pd.concat(post_enc)\n",
    "    post_enc[\"phase\"] = \"Post\"\n",
    "    # Combine encounter dataframes\n",
    "    enc_list = [exp_enc, control_enc, pre_enc, post_enc]\n",
    "    enc = pd.concat(enc_list)\n",
    "    # Add colonyID\n",
    "    enc[\"colony\"] = colonyID\n",
    "    # Sort by values\n",
    "    enc = enc.sort_values(\n",
    "        by=[\"colony\", \"phase\", \"exp_day\", \"focalID\", \"AntID\"]\n",
    "    ).reset_index(drop=True)\n",
    "    enc = enc[[\"colony\", \"phase\", \"exp_day\", \"focalID\", \"AntID\", \"encounters\"]]\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Colony Cfel 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_myrmidon = \"/media/egeorge/Elements/Woundcare Experiment1/Cfell_wound_col42.myrmidon\"\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "\n",
    "# Thresholds\n",
    "encounter_threshold = 300  # threshold for counting as an encounter\n",
    "away_threshold = 1000  # Threshold for counting as the end of an encounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To run the function over all the ants, we will need to get the list of antIDs\n",
    "# ants = list(exp.Ants.keys())\n",
    "# Create list of focal ants\n",
    "focal = [106, 63, 23, 53, 19]\n",
    "# Create list of lists of all other antIDs excluding each focal ID\n",
    "# others = [list(set(ants) - set([x])) for x in focal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experimental phase\n",
    "day_starts_exp = [\n",
    "    datetime(2022, 5, 2, 16, 3).astimezone(tz=None),\n",
    "    datetime(2022, 5, 3, 15, 53).astimezone(tz=None),\n",
    "    datetime(2022, 5, 4, 15, 50).astimezone(tz=None),\n",
    "    datetime(2022, 5, 5, 15, 50).astimezone(tz=None),\n",
    "    datetime(2022, 5, 6, 15, 55).astimezone(tz=None),\n",
    "]\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "exp_days = [1, 2, 3, 4, 5]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control Phase\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2022, 5, 1, 15, 54).astimezone(tz=None), 5)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre experimental phase\n",
    "day_starts_pre = [\n",
    "    datetime(2022, 5, 2, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 3, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 4, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 5, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 6, 9, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase\n",
    "day_starts_post = [\n",
    "    datetime(2022, 5, 3, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 4, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 5, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 6, 9, 0).astimezone(tz=None),\n",
    "    datetime(2022, 5, 7, 9, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel42_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel42\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel42_enc.to_csv(\"Cfel42_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Colony Cfel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_myrmidon = (\n",
    "    \"/media/egeorge/Elements/Woundcare Experiment2/woundcare_cfell1_T2.myrmidon\"\n",
    ")\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "# Thresholds\n",
    "encounter_threshold = 300  # threshold for counting as an encounter\n",
    "away_threshold = 1000  # Threshold for counting as the end of an encounter\n",
    "# Focal Ants\n",
    "focal = [87, 37, 58, 38, 3]\n",
    "exp_days = [1, 2, 3, 4, 5]\n",
    "# Experimental Phase list\n",
    "day_starts_exp = [\n",
    "    datetime(2022, 6, 5, 14, 57).astimezone(tz=None),\n",
    "    datetime(2022, 6, 6, 14, 30).astimezone(tz=None),\n",
    "    datetime(2022, 6, 7, 14, 49).astimezone(tz=None),\n",
    "    datetime(2022, 6, 8, 14, 43).astimezone(tz=None),\n",
    "    datetime(2022, 6, 9, 15, 5).astimezone(tz=None),\n",
    "]\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control phase list\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2022, 6, 4, 14, 48).astimezone(tz=None), 5)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre Experimental phase list\n",
    "day_starts_pre = [\n",
    "    datetime(2022, 6, 5, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 6, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 7, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 8, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 9, 8, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase list\n",
    "day_starts_post = [\n",
    "    datetime(2022, 6, 6, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 7, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 8, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 9, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 10, 8, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel1_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel1_enc.to_csv(\"Cfel1_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Colony Cfel 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_myrmidon = (\n",
    "    \"/media/egeorge/Elements/Woundcare Experiment3/woundcare_cfell54_T3.myrmidon\"\n",
    ")\n",
    "exp = fm.Experiment.Open(f_myrmidon)\n",
    "# Thresholds\n",
    "encounter_threshold = 300  # threshold for counting as an encounter\n",
    "away_threshold = 1000  # Threshold for counting as the end of an encounter\n",
    "# Focal Ants\n",
    "focal = [108, 114, 62, 12]\n",
    "exp_days = [1, 2, 3, 4]\n",
    "# Experimental Phase list\n",
    "day_starts_exp = [\n",
    "    datetime(2022, 6, 20, 14, 35).astimezone(tz=None),\n",
    "    datetime(2022, 6, 21, 14, 21).astimezone(tz=None),\n",
    "    datetime(2022, 6, 22, 14, 28).astimezone(tz=None),\n",
    "    datetime(2022, 6, 23, 14, 14).astimezone(tz=None),\n",
    "]\n",
    "day_ends_exp = [day_time + timedelta(hours=6) for day_time in day_starts_exp]\n",
    "\n",
    "disp_list_exp = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_exp, day_ends_exp, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Control phase list\n",
    "day_starts_control = list(\n",
    "    np.repeat(datetime(2022, 6, 19, 14, 25).astimezone(tz=None), 4)\n",
    ")\n",
    "day_ends_control = [day_time + timedelta(hours=6) for day_time in day_starts_control]\n",
    "\n",
    "disp_list_control = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_control, day_ends_control, focal, exp_days\n",
    "    )\n",
    "]\n",
    "\n",
    "# Pre Experimental phase list\n",
    "day_starts_pre = [\n",
    "    datetime(2022, 6, 20, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 21, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 22, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 23, 8, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_pre = [day_time + timedelta(hours=6) for day_time in day_starts_pre]\n",
    "\n",
    "disp_list_pre = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(day_starts_pre, day_ends_pre, focal, exp_days)\n",
    "]\n",
    "\n",
    "# Post experimental phase list\n",
    "day_starts_post = [\n",
    "    datetime(2022, 6, 21, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 22, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 23, 8, 0).astimezone(tz=None),\n",
    "    datetime(2022, 6, 24, 8, 0).astimezone(tz=None),\n",
    "]\n",
    "day_ends_post = [day_time + timedelta(hours=6) for day_time in day_starts_post]\n",
    "\n",
    "disp_list_post = [\n",
    "    (start, end, exp, focal, exp_day, encounter_threshold, away_threshold)\n",
    "    for start, end, focal, exp_day in zip(\n",
    "        day_starts_post, day_ends_post, focal, exp_days\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel54_enc = calculate_encounters_cluster(\n",
    "    disp_list_exp, disp_list_control, disp_list_pre, disp_list_post, \"Cfel54\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfel54_enc.to_csv(\"Cfel54_AllAnts_Focal_Encounters.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
